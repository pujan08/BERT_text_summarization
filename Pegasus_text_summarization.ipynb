{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "174c2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece\n",
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e129138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include libraries\n",
    "import sentencepiece\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79ddcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Load the PEGASUS model\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c3a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve text from the provided URL\n",
    "def get_text_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = ' '.join([p.text for p in soup.find_all('p')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810ded0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize text using PEGASUS\n",
    "def summarize_with_pegasus(text):\n",
    "    model_name = \"google/pegasus-large\"\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "    model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer([text], max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53cef5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to extract text from\n",
    "url = \"https://en.wikipedia.org/wiki/Automatic_summarization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d95475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve text from the URL\n",
    "text = get_text_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2902ceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Summarize the text using PEGASUS\n",
    "summary = summarize_with_pegasus(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "239fc7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Image summarization is the subject of ongoing research; existing approaches typically attempt to display the most representative images from a given image collection, or generate a video that only includes the most important content from the entire collection.[2][3][4] Video summarization algorithms identify and extract from the original video content the most important frames (key-frames), and/or the most important video segments (key-shots), normally in a temporally ordered fashion.[5][6][7][8] Video summaries simply retain a carefully selected subset of the original video frames and, therefore, are not identical to the output of video synopsis algorithms, where new video frames are being synthesized based on the original video content.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171af355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
